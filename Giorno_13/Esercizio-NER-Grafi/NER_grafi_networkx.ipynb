{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f844c1b",
   "metadata": {},
   "source": [
    "# üîí Sistema di Anonimizzazione con NER e Grafi NetworkX\n",
    "# \n",
    "# üìã Panoramica\n",
    "# \n",
    "# Questo notebook implementa un sistema avanzato di anonimizzazione che combina:\n",
    "# - **üîç Named Entity Recognition (NER)** per identificare entit√† semantiche\n",
    "# - **üìù Espressioni Regolari** per pattern specifici italiani\n",
    "# - **üï∏Ô∏è Grafi NetworkX** per visualizzare le relazioni tra entit√†\n",
    "# \n",
    "# üéØ Obiettivi\n",
    "# 1. Identificare e mascherare informazioni sensibili (PII)\n",
    "# 2. Creare un grafo delle relazioni tra entit√†\n",
    "# 3. Visualizzare i risultati in modo interattivo\n",
    "# \n",
    "# üõ†Ô∏è Tecnologie utilizzate\n",
    "# - `transformers` - Modelli NER pre-addestrati\n",
    "# - `networkx` - Creazione e manipolazione di grafi\n",
    "# - `matplotlib` - Visualizzazione dei grafi\n",
    "# - `streamlit` - Interfaccia utente (opzionale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5f3a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installa le dipendenze necessarie\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"Installa le dipendenze necessarie\"\"\"\n",
    "    requirements = [\n",
    "        'transformers',\n",
    "        'torch',\n",
    "        'networkx',\n",
    "        'matplotlib',\n",
    "        'streamlit',\n",
    "        'pandas',\n",
    "        'numpy'\n",
    "    ]\n",
    "    \n",
    "    for package in requirements:\n",
    "        try:\n",
    "            __import__(package)\n",
    "            print(f\"‚úÖ {package} gi√† installato\")\n",
    "        except ImportError:\n",
    "            print(f\"üì¶ Installazione {package}...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "            print(f\"‚úÖ {package} installato con successo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c05ee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importazioni principali\n",
    "import re\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Tuple, List, Optional\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurazione matplotlib per grafici pi√π belli\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['axes.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06796fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öôÔ∏è Configurazione completata\n",
      "üìù 10 pattern regex definiti\n",
      "üé® 16 colori per entit√† configurati\n"
     ]
    }
   ],
   "source": [
    "# Configurazione principale\n",
    "class Config:\n",
    "    \"\"\"Configurazioni del sistema di anonimizzazione\"\"\"\n",
    "    \n",
    "    # Modello NER (scegli in base alle tue esigenze)\n",
    "    NER_MODEL = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "    # Alternativa per italiano: \"dbmdz/bert-base-italian-cased-ner\"\n",
    "    \n",
    "    # Soglia di confidenza per NER\n",
    "    NER_CONFIDENCE_THRESHOLD = 0.5\n",
    "    \n",
    "    # Impostazioni visualizzazione\n",
    "    FIGURE_SIZE = (14, 10)\n",
    "    DPI = 300\n",
    "\n",
    "# Pattern regex per entit√† italiane\n",
    "REGEX_PATTERNS = {\n",
    "    \"CODICE_FISCALE\": r'\\b[A-Z]{6}\\d{2}[A-Z]\\d{2}[A-Z]\\d{3}[A-Z]\\b',\n",
    "    \"PARTITA_IVA\": r'\\b\\d{11}\\b',\n",
    "    \"EMAIL\": r'\\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\\b',\n",
    "    \"TELEFONO\": r'\\b(?:\\+39\\s?)?(?:0\\d{1,4}[-.\\s]?)?\\d{6,8}\\b',\n",
    "    \"DATA\": r'\\b(?:0[1-9]|[12][0-9]|3[01])[\\/\\-\\.](0[1-9]|1[012])[\\/\\-\\.](?:19|20)\\d{2}\\b',\n",
    "    \"IBAN\": r'\\b[A-Z]{2}\\d{2}[A-Z0-9]{4}\\d{7}[A-Z0-9]{0,16}\\b',\n",
    "    \"IMPORTO\": r'\\b\\d{1,3}(?:\\.\\d{3})*(?:,\\d{2})?\\s?‚Ç¨|\\b‚Ç¨\\s?\\d{1,3}(?:\\.\\d{3})*(?:,\\d{2})?\\b',\n",
    "    \"INDIRIZZO\": r'\\b(?:Via|Piazza|Viale|Corso|Largo|Vicolo)\\s+[A-Za-z\\s]+\\d+\\b',\n",
    "    \"CAP\": r'\\b\\d{5}\\b',\n",
    "    \"CARTA_CREDITO\": r'\\b(?:\\d{4}[-.\\s]?){3}\\d{4}\\b',\n",
    "}\n",
    "\n",
    "# Colori per la visualizzazione\n",
    "ENTITY_COLORS = {\n",
    "    'PERSONA': '#FF6B6B',      # Rosso corallo\n",
    "    'LUOGO': '#4ECDC4',        # Turchese\n",
    "    'ORGANIZZAZIONE': '#45B7D1', # Blu\n",
    "    'EMAIL': '#96CEB4',        # Verde menta\n",
    "    'TELEFONO': '#FFEAA7',     # Giallo\n",
    "    'CODICE_FISCALE': '#DDA0DD', # Prugna\n",
    "    'PARTITA_IVA': '#98D8C8',  # Acqua marina\n",
    "    'DATA': '#F7DC6F',         # Giallo oro\n",
    "    'IBAN': '#BB8FCE',         # Lavanda\n",
    "    'CARTA_CREDITO': '#F1948A', # Salmone\n",
    "    'INDIRIZZO': '#85C1E9',    # Blu cielo\n",
    "    'IMPORTO': '#82E0AA',      # Verde chiaro\n",
    "    'CAP': '#F8C471',          # Arancione\n",
    "    'Documento': '#D5DBDB',    # Grigio chiaro\n",
    "    'Categoria': '#AED6F1',    # Blu pastello\n",
    "    'default': '#BDC3C7'       # Grigio\n",
    "}\n",
    "\n",
    "print(\"‚öôÔ∏è Configurazione completata\")\n",
    "print(f\"üìù {len(REGEX_PATTERNS)} pattern regex definiti\")\n",
    "print(f\"üé® {len(ENTITY_COLORS)} colori per entit√† configurati\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af43efe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Classe NERAnonimizer definita con successo!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "class NERAnonimizer:\n",
    "    \"\"\"üîí Anonimizzatore avanzato con NER, regex e grafi\"\"\"\n",
    "    \n",
    "    def __init__(self, use_ner: bool = True, verbose: bool = True):\n",
    "        \"\"\"\n",
    "        Inizializza l'anonimizzatore\n",
    "        \n",
    "        Args:\n",
    "            use_ner: Se utilizzare il modello NER\n",
    "            verbose: Se stampare messaggi di debug\n",
    "        \"\"\"\n",
    "        self.regex_patterns = REGEX_PATTERNS\n",
    "        self._ner_pipe = None\n",
    "        self.use_ner = use_ner\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Inizializza il grafo diretto\n",
    "        self.G = nx.DiGraph()\n",
    "        \n",
    "        # Statistiche\n",
    "        self.stats = {\n",
    "            'documenti_processati': 0,\n",
    "            'entit√†_trovate': 0,\n",
    "            'tempo_elaborazione': 0\n",
    "        }\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(\"üöÄ NERAnonimizer inizializzato\")\n",
    "            print(f\"üß† NER: {'Attivo' if use_ner else 'Disattivo'}\")\n",
    "            print(f\"üìä Grafo inizializzato: {self.G.number_of_nodes()} nodi\")\n",
    "    \n",
    "    @property\n",
    "    def ner_pipe(self):\n",
    "        \"\"\"Lazy loading del modello NER\"\"\"\n",
    "        if not self.use_ner:\n",
    "            return None\n",
    "            \n",
    "        if self._ner_pipe is None:\n",
    "            if self.verbose:\n",
    "                print(\"üì• Caricamento modello NER...\")\n",
    "            \n",
    "            try:\n",
    "                from transformers import pipeline\n",
    "                self._ner_pipe = pipeline(\n",
    "                    \"ner\",\n",
    "                    model=Config.NER_MODEL,\n",
    "                    aggregation_strategy=\"simple\"\n",
    "                )\n",
    "                if self.verbose:\n",
    "                    print(\"‚úÖ Modello NER caricato con successo\")\n",
    "            except Exception as e:\n",
    "                if self.verbose:\n",
    "                    print(f\"‚ùå Errore caricamento NER: {e}\")\n",
    "                    print(\"üîÑ Continuando solo con regex...\")\n",
    "                return None\n",
    "        \n",
    "        return self._ner_pipe\n",
    "    \n",
    "    def add_entity_to_graph(self, entity_id: str, entity_type: str, original_text: str):\n",
    "        \"\"\"Aggiunge un'entit√† al grafo\"\"\"\n",
    "        # Aggiungi nodo per l'entit√†\n",
    "        self.G.add_node(entity_id, \n",
    "                       tipo=entity_type, \n",
    "                       testo_originale=original_text,\n",
    "                       timestamp=datetime.now().isoformat())\n",
    "        \n",
    "        # Aggiungi nodo per il tipo se non esiste\n",
    "        if not self.G.has_node(entity_type):\n",
    "            self.G.add_node(entity_type, tipo=\"Categoria\")\n",
    "        \n",
    "        # Collega l'entit√† al suo tipo\n",
    "        self.G.add_edge(entity_id, entity_type, relazione=\"√®_di_tipo\")\n",
    "    \n",
    "    def add_document_to_graph(self, doc_id: str, entities: Dict):\n",
    "        \"\"\"Aggiunge un documento e le sue entit√† al grafo\"\"\"\n",
    "        # Aggiungi nodo documento\n",
    "        self.G.add_node(doc_id, \n",
    "                       tipo=\"Documento\",\n",
    "                       num_entit√†=len(entities),\n",
    "                       timestamp=datetime.now().isoformat())\n",
    "        \n",
    "        # Collega documento alle entit√† trovate\n",
    "        for entity_id in entities.keys():\n",
    "            if self.G.has_node(entity_id):\n",
    "                self.G.add_edge(doc_id, entity_id, relazione=\"contiene\")\n",
    "    \n",
    "    def mask_with_regex(self, text: str) -> Tuple[str, Dict]:\n",
    "        \"\"\"üîç Applica mascheramento con espressioni regolari\"\"\"\n",
    "        masked_text = text\n",
    "        found_entities = {}\n",
    "        \n",
    "        # Ordina pattern per lunghezza (pi√π lunghi prima)\n",
    "        sorted_patterns = sorted(\n",
    "            self.regex_patterns.items(),\n",
    "            key=lambda item: len(item[1]),\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        for label, pattern in sorted_patterns:\n",
    "            matches = list(re.finditer(pattern, masked_text, flags=re.IGNORECASE))\n",
    "            for match in reversed(matches):\n",
    "                original = match.group()\n",
    "                if original.startswith('[') and original.endswith(']'):\n",
    "                    continue\n",
    "                \n",
    "                placeholder = f\"[{label}_{len(found_entities)}]\"\n",
    "                found_entities[placeholder] = original\n",
    "                \n",
    "                # Aggiungi al grafo\n",
    "                self.add_entity_to_graph(placeholder, label, original)\n",
    "                \n",
    "                masked_text = masked_text[:match.start()] + placeholder + masked_text[match.end():]\n",
    "        \n",
    "        return masked_text, found_entities\n",
    "    \n",
    "    def mask_with_ner(self, text: str) -> Tuple[str, Dict]:\n",
    "        \"\"\"üß† Applica mascheramento con NER\"\"\"\n",
    "        if not self.ner_pipe:\n",
    "            return text, {}\n",
    "        \n",
    "        try:\n",
    "            entities = self.ner_pipe(text)\n",
    "            entity_map = {}\n",
    "            \n",
    "            sorted_entities = sorted(entities, key=lambda x: x['start'], reverse=True)\n",
    "            \n",
    "            for ent in sorted_entities:\n",
    "                if ent['score'] > Config.NER_CONFIDENCE_THRESHOLD:\n",
    "                    label = ent['entity_group']\n",
    "                    original_text = text[ent['start']:ent['end']]\n",
    "                    \n",
    "                    if original_text.startswith('[') and original_text.endswith(']'):\n",
    "                        continue\n",
    "                    \n",
    "                    placeholder = f\"[{label}_{len(entity_map)}]\"\n",
    "                    entity_map[placeholder] = original_text\n",
    "                    \n",
    "                    # Aggiungi al grafo\n",
    "                    self.add_entity_to_graph(placeholder, label, original_text)\n",
    "                    \n",
    "                    text = text[:ent['start']] + placeholder + text[ent['end']:]\n",
    "            \n",
    "            return text, entity_map\n",
    "        \n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"‚ùå Errore NER: {e}\")\n",
    "            return text, {}\n",
    "    \n",
    "    def anonymize(self, text: str, doc_id: str = None) -> Tuple[str, Dict]:\n",
    "        \"\"\"üîí Pipeline completa di anonimizzazione\"\"\"\n",
    "        if not text or not text.strip():\n",
    "            return text, {}\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Regex prima, poi NER\n",
    "        masked_text, regex_entities = self.mask_with_regex(text)\n",
    "        final_text, ner_entities = self.mask_with_ner(masked_text)\n",
    "        \n",
    "        # Combina entit√†\n",
    "        all_entities = {**regex_entities, **ner_entities}\n",
    "        \n",
    "        # Aggiungi documento al grafo se specificato\n",
    "        if doc_id:\n",
    "            self.add_document_to_graph(doc_id, all_entities)\n",
    "        \n",
    "        # Aggiorna statistiche\n",
    "        self.stats['documenti_processati'] += 1\n",
    "        self.stats['entit√†_trovate'] += len(all_entities)\n",
    "        self.stats['tempo_elaborazione'] += (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        if self.verbose:\n",
    "            print(f\"‚úÖ Processato documento: {len(all_entities)} entit√† trovate\")\n",
    "        \n",
    "        return final_text, all_entities\n",
    "    \n",
    "    def get_graph_stats(self) -> Dict:\n",
    "        \"\"\"üìä Statistiche del grafo\"\"\"\n",
    "        return {\n",
    "            \"numero_nodi\": self.G.number_of_nodes(),\n",
    "            \"numero_collegamenti\": self.G.number_of_edges(),\n",
    "            \"tipi_entit√†\": list(set([data.get('tipo', 'Sconosciuto') \n",
    "                                   for node, data in self.G.nodes(data=True)])),\n",
    "            \"entit√†_per_tipo\": {tipo: len([n for n, d in self.G.nodes(data=True) \n",
    "                                         if d.get('tipo') == tipo]) \n",
    "                               for tipo in set([data.get('tipo', 'Sconosciuto') \n",
    "                                              for node, data in self.G.nodes(data=True)])}\n",
    "        }\n",
    "    \n",
    "    def visualize_graph(self, \n",
    "                       layout_type: str = 'spring',\n",
    "                       figsize: Tuple[int, int] = (14, 10),\n",
    "                       save_path: Optional[str] = None,\n",
    "                       show_labels: bool = True,\n",
    "                       title: str = \"üï∏Ô∏è Grafo delle Entit√† Estratte\") -> None:\n",
    "        \"\"\"\n",
    "        üé® Visualizza il grafo con stile avanzato\n",
    "        \n",
    "        Args:\n",
    "            layout_type: Tipo di layout ('spring', 'circular', 'kamada_kawai')\n",
    "            figsize: Dimensioni della figura\n",
    "            save_path: Percorso per salvare l'immagine\n",
    "            show_labels: Se mostrare le etichette\n",
    "            title: Titolo del grafo\n",
    "        \"\"\"\n",
    "        if self.G.number_of_nodes() == 0:\n",
    "            print(\"‚ö†Ô∏è Il grafo √® vuoto!\")\n",
    "            return\n",
    "        \n",
    "        # Crea figura con subplot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize, gridspec_kw={'width_ratios': [3, 1]})\n",
    "        \n",
    "        # === GRAFO PRINCIPALE ===\n",
    "        \n",
    "        # Crea il layout\n",
    "        layouts = {\n",
    "            'spring': lambda: nx.spring_layout(self.G, k=3, iterations=50),\n",
    "            'circular': lambda: nx.circular_layout(self.G),\n",
    "            'kamada_kawai': lambda: nx.kamada_kawai_layout(self.G),\n",
    "            'random': lambda: nx.random_layout(self.G)\n",
    "        }\n",
    "        \n",
    "        pos = layouts.get(layout_type, layouts['spring'])()\n",
    "        \n",
    "        # Prepara colori e dimensioni dei nodi\n",
    "        node_colors = []\n",
    "        node_sizes = []\n",
    "        node_types = []\n",
    "        \n",
    "        for node, data in self.G.nodes(data=True):\n",
    "            node_type = data.get('tipo', 'default')\n",
    "            node_types.append(node_type)\n",
    "            node_colors.append(ENTITY_COLORS.get(node_type, ENTITY_COLORS['default']))\n",
    "            \n",
    "            # Dimensioni diverse per tipi diversi\n",
    "            if node_type == 'Documento':\n",
    "                node_sizes.append(2500)\n",
    "            elif node_type == 'Categoria':\n",
    "                node_sizes.append(1800)\n",
    "            else:\n",
    "                node_sizes.append(1200)\n",
    "        \n",
    "        # Disegna i nodi\n",
    "        nx.draw_networkx_nodes(self.G, pos, \n",
    "                              node_color=node_colors,\n",
    "                              node_size=node_sizes,\n",
    "                              alpha=0.8,\n",
    "                              edgecolors='white',\n",
    "                              linewidths=2,\n",
    "                              ax=ax1)\n",
    "        \n",
    "        # Disegna gli archi con stili diversi\n",
    "        edge_colors = []\n",
    "        edge_styles = []\n",
    "        for edge in self.G.edges(data=True):\n",
    "            relation = edge[2].get('relazione', 'default')\n",
    "            if relation == 'contiene':\n",
    "                edge_colors.append('#2C3E50')\n",
    "                edge_styles.append('solid')\n",
    "            else:\n",
    "                edge_colors.append('#7F8C8D')\n",
    "                edge_styles.append('dashed')\n",
    "        \n",
    "        nx.draw_networkx_edges(self.G, pos,\n",
    "                              edge_color=edge_colors,\n",
    "                              arrows=True,\n",
    "                              arrowsize=25,\n",
    "                              alpha=0.7,\n",
    "                              width=2,\n",
    "                              ax=ax1)\n",
    "        \n",
    "        # Etichette se richieste\n",
    "        if show_labels:\n",
    "            labels = {}\n",
    "            for node, data in self.G.nodes(data=True):\n",
    "                node_type = data.get('tipo', 'Unknown')\n",
    "                if node_type in ['Categoria', 'Documento']:\n",
    "                    labels[node] = node\n",
    "                else:\n",
    "                    labels[node] = node_type\n",
    "            \n",
    "            nx.draw_networkx_labels(self.G, pos, labels, \n",
    "                                   font_size=9, \n",
    "                                   font_weight='bold',\n",
    "                                   font_color='white',\n",
    "                                   ax=ax1)\n",
    "        \n",
    "        ax1.set_title(title, fontsize=16, fontweight='bold', pad=20)\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # === STATISTICHE E LEGENDA ===\n",
    "        \n",
    "        stats = self.get_graph_stats()\n",
    "        \n",
    "        # Prepara dati per il grafico a barre\n",
    "        types_in_graph = [t for t in stats['entit√†_per_tipo'].keys() if t != 'Sconosciuto']\n",
    "        counts = [stats['entit√†_per_tipo'][t] for t in types_in_graph]\n",
    "        colors_bar = [ENTITY_COLORS.get(t, ENTITY_COLORS['default']) for t in types_in_graph]\n",
    "        \n",
    "        # Grafico a barre orizzontale\n",
    "        y_pos = np.arange(len(types_in_graph))\n",
    "        bars = ax2.barh(y_pos, counts, color=colors_bar, alpha=0.8, edgecolor='white')\n",
    "        \n",
    "        # Personalizza il grafico delle statistiche\n",
    "        ax2.set_yticks(y_pos)\n",
    "        ax2.set_yticklabels(types_in_graph, fontsize=9)\n",
    "        ax2.set_xlabel('Numero di Entit√†', fontsize=10)\n",
    "        ax2.set_title('üìä Distribuzione Entit√†', fontsize=12, fontweight='bold')\n",
    "        ax2.grid(axis='x', alpha=0.3)\n",
    "        \n",
    "        # Aggiungi valori sulle barre\n",
    "        for i, (bar, count) in enumerate(zip(bars, counts)):\n",
    "            ax2.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "                    str(count), ha='left', va='center', fontweight='bold')\n",
    "        \n",
    "        # Informazioni generali\n",
    "        info_text = f\"\"\"\n",
    "üìä STATISTICHE GENERALI\n",
    "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "üîó Nodi totali: {stats['numero_nodi']}\n",
    "üîó Collegamenti: {stats['numero_collegamenti']}\n",
    "üìÑ Documenti: {self.stats['documenti_processati']}\n",
    "üéØ Entit√† trovate: {self.stats['entit√†_trovate']}\n",
    "‚è±Ô∏è Tempo elaborazione: {self.stats['tempo_elaborazione']:.2f}s\n",
    "        \"\"\"\n",
    "        \n",
    "        ax2.text(0.02, 0.02, info_text, transform=ax2.transAxes, \n",
    "                fontsize=8, verticalalignment='bottom',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightgray', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Salva se richiesto\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=Config.DPI, bbox_inches='tight', \n",
    "                       facecolor='white', edgecolor='none')\n",
    "            print(f\"üíæ Grafo salvato in: {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    def print_detailed_summary(self):\n",
    "        \"\"\"üìã Stampa un riassunto dettagliato del sistema\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üîí SISTEMA DI ANONIMIZZAZIONE - REPORT DETTAGLIATO\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        stats = self.get_graph_stats()\n",
    "        \n",
    "        print(f\"\\nüìä STATISTICHE GENERALI\")\n",
    "        print(\"-\" * 30)\n",
    "        print(f\"üîó Nodi nel grafo: {stats['numero_nodi']}\")\n",
    "        print(f\"üîó Collegamenti: {stats['numero_collegamenti']}\")\n",
    "        print(f\"üìÑ Documenti processati: {self.stats['documenti_processati']}\")\n",
    "        print(f\"üéØ Entit√† totali trovate: {self.stats['entit√†_trovate']}\")\n",
    "        print(f\"‚è±Ô∏è Tempo elaborazione: {self.stats['tempo_elaborazione']:.2f} secondi\")\n",
    "        \n",
    "        print(f\"\\nüìã DISTRIBUZIONE PER TIPO\")\n",
    "        print(\"-\" * 30)\n",
    "        for tipo, count in sorted(stats['entit√†_per_tipo'].items(), key=lambda x: x[1], reverse=True):\n",
    "            emoji = \"üìÑ\" if tipo == \"Documento\" else \"üìÇ\" if tipo == \"Categoria\" else \"üéØ\"\n",
    "            print(f\"{emoji} {tipo}: {count}\")\n",
    "        \n",
    "        print(f\"\\nüìÑ DETTAGLI ENTIT√Ä\")\n",
    "        print(\"-\" * 30)\n",
    "        for node, data in self.G.nodes(data=True):\n",
    "            tipo = data.get('tipo', 'Sconosciuto')\n",
    "            testo = data.get('testo_originale', 'N/A')\n",
    "            \n",
    "            # Tronca il testo se troppo lungo\n",
    "            if len(testo) > 40:\n",
    "                testo = testo[:40] + \"...\"\n",
    "            \n",
    "            timestamp = data.get('timestamp', 'N/A')\n",
    "            print(f\"   üî∏ {node} ({tipo})\")\n",
    "            print(f\"      üìù Testo: {testo}\")\n",
    "            if timestamp != 'N/A':\n",
    "                print(f\"      ‚è∞ Creato: {timestamp}\")\n",
    "    \n",
    "    def export_results(self, filepath: str, format: str = 'json'):\n",
    "        \"\"\"üíæ Esporta i risultati in vari formati\"\"\"\n",
    "        if format == 'json':\n",
    "            import json\n",
    "            \n",
    "            # Prepara dati per JSON\n",
    "            export_data = {\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'statistics': self.get_graph_stats(),\n",
    "                'system_stats': self.stats,\n",
    "                'nodes': [\n",
    "                    {\n",
    "                        'id': node,\n",
    "                        'type': data.get('tipo', 'Unknown'),\n",
    "                        'original_text': data.get('testo_originale', 'N/A'),\n",
    "                        'timestamp': data.get('timestamp', 'N/A')\n",
    "                    }\n",
    "                    for node, data in self.G.nodes(data=True)\n",
    "                ],\n",
    "                'edges': [\n",
    "                    {\n",
    "                        'source': edge[0],\n",
    "                        'target': edge[1],\n",
    "                        'relation': edge[2].get('relazione', 'unknown')\n",
    "                    }\n",
    "                    for edge in self.G.edges(data=True)\n",
    "                ]\n",
    "            }\n",
    "            \n",
    "            with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"üíæ Risultati esportati in JSON: {filepath}\")\n",
    "        \n",
    "        elif format == 'csv':\n",
    "            # Esporta entit√† in CSV\n",
    "            entities_data = []\n",
    "            for node, data in self.G.nodes(data=True):\n",
    "                entities_data.append({\n",
    "                    'ID': node,\n",
    "                    'Tipo': data.get('tipo', 'Unknown'),\n",
    "                    'Testo_Originale': data.get('testo_originale', 'N/A'),\n",
    "                    'Timestamp': data.get('timestamp', 'N/A')\n",
    "                })\n",
    "            \n",
    "            df = pd.DataFrame(entities_data)\n",
    "            df.to_csv(filepath, index=False, encoding='utf-8')\n",
    "            print(f\"üíæ Risultati esportati in CSV: {filepath}\")\n",
    "        \n",
    "        elif format == 'gexf':\n",
    "            # Esporta grafo in formato GEXF per Gephi\n",
    "            nx.write_gexf(self.G, filepath)\n",
    "            print(f\"üíæ Grafo esportato in GEXF: {filepath}\")\n",
    "    \n",
    "    def clear_graph(self):\n",
    "        \"\"\"üßπ Pulisce il grafo e resetta le statistiche\"\"\"\n",
    "        self.G.clear()\n",
    "        self.stats = {\n",
    "            'documenti_processati': 0,\n",
    "            'entit√†_trovate': 0,\n",
    "            'tempo_elaborazione': 0\n",
    "        }\n",
    "        if self.verbose:\n",
    "            print(\"üßπ Grafo e statistiche resettati\")\n",
    "\n",
    "print(\"‚úÖ Classe NERAnonimizer definita con successo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c10929f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Inizializzazione sistema di anonimizzazione...\n",
      "üöÄ NERAnonimizer inizializzato\n",
      "üß† NER: Disattivo\n",
      "üìä Grafo inizializzato: 0 nodi\n",
      "\n",
      "üìÑ TESTO ORIGINALE:\n",
      "--------------------------------------------------\n",
      "\n",
      "Mario Rossi, nato il 15/03/1985, risiede in Via Roma 123, Milano.\n",
      "Il suo numero di telefono √® 02-1234567 e la sua email √® mario.rossi@gmail.com.\n",
      "Ha un codice fiscale RSSMRA85C15F205X e partita IVA 12345678901.\n",
      "Il suo IBAN √® IT60X0542811101000000123456 e paga sempre con la carta 4532-1234-5678-9012.\n",
      "\n",
      "\n",
      "üîÑ Processamento in corso...\n",
      "‚úÖ Processato documento: 8 entit√† trovate\n",
      "\n",
      "üîí TESTO ANONIMIZZATO:\n",
      "--------------------------------------------------\n",
      "\n",
      "Mario Rossi, nato il [DATA_0], risiede in [INDIRIZZO_1], Milano.\n",
      "Il suo numero di telefono √® [TELEFONO_4] e la sua email √® [EMAIL_2].\n",
      "Ha un codice fiscale [CODICE_FISCALE_5] e partita IVA [PARTITA_IVA_7].\n",
      "Il suo IBAN √® [IBAN_3] e paga sempre con la carta [CARTA_CREDITO_6].\n",
      "\n",
      "\n",
      "üéØ ENTIT√Ä IDENTIFICATE (8):\n",
      "--------------------------------------------------\n",
      "üî∏ DATA: 15/03/1985 ‚Üí [DATA_0]\n",
      "üî∏ INDIRIZZO: Via Roma 123 ‚Üí [INDIRIZZO_1]\n",
      "üî∏ EMAIL: mario.rossi@gmail.com ‚Üí [EMAIL_2]\n",
      "üî∏ IBAN: IT60X0542811101000000123456 ‚Üí [IBAN_3]\n",
      "üî∏ TELEFONO: 02-1234567 ‚Üí [TELEFONO_4]\n",
      "üî∏ CODICE: RSSMRA85C15F205X ‚Üí [CODICE_FISCALE_5]\n",
      "üî∏ CARTA: 4532-1234-5678-9012 ‚Üí [CARTA_CREDITO_6]\n",
      "üî∏ PARTITA: 12345678901 ‚Üí [PARTITA_IVA_7]\n",
      "\n",
      "======================================================================\n",
      "üîí SISTEMA DI ANONIMIZZAZIONE - REPORT DETTAGLIATO\n",
      "======================================================================\n",
      "\n",
      "üìä STATISTICHE GENERALI\n",
      "------------------------------\n",
      "üîó Nodi nel grafo: 17\n",
      "üîó Collegamenti: 16\n",
      "üìÑ Documenti processati: 1\n",
      "üéØ Entit√† totali trovate: 8\n",
      "‚è±Ô∏è Tempo elaborazione: 0.00 secondi\n",
      "\n",
      "üìã DISTRIBUZIONE PER TIPO\n",
      "------------------------------\n",
      "üìÇ Categoria: 8\n",
      "üéØ INDIRIZZO: 1\n",
      "üéØ TELEFONO: 1\n",
      "üéØ EMAIL: 1\n",
      "üìÑ Documento: 1\n",
      "üéØ PARTITA_IVA: 1\n",
      "üéØ DATA: 1\n",
      "üéØ CODICE_FISCALE: 1\n",
      "üéØ IBAN: 1\n",
      "üéØ CARTA_CREDITO: 1\n",
      "\n",
      "üìÑ DETTAGLI ENTIT√Ä\n",
      "------------------------------\n",
      "   üî∏ [DATA_0] (DATA)\n",
      "      üìù Testo: 15/03/1985\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864232\n",
      "   üî∏ DATA (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [INDIRIZZO_1] (INDIRIZZO)\n",
      "      üìù Testo: Via Roma 123\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864307\n",
      "   üî∏ INDIRIZZO (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [EMAIL_2] (EMAIL)\n",
      "      üìù Testo: mario.rossi@gmail.com\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864334\n",
      "   üî∏ EMAIL (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [IBAN_3] (IBAN)\n",
      "      üìù Testo: IT60X0542811101000000123456\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864353\n",
      "   üî∏ IBAN (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [TELEFONO_4] (TELEFONO)\n",
      "      üìù Testo: 02-1234567\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864374\n",
      "   üî∏ TELEFONO (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [CODICE_FISCALE_5] (CODICE_FISCALE)\n",
      "      üìù Testo: RSSMRA85C15F205X\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864391\n",
      "   üî∏ CODICE_FISCALE (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [CARTA_CREDITO_6] (CARTA_CREDITO)\n",
      "      üìù Testo: 4532-1234-5678-9012\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864407\n",
      "   üî∏ CARTA_CREDITO (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [PARTITA_IVA_7] (PARTITA_IVA)\n",
      "      üìù Testo: 12345678901\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864423\n",
      "   üî∏ PARTITA_IVA (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ documento_esempio_1 (Documento)\n",
      "      üìù Testo: N/A\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864440\n",
      "\n",
      "üé® Generazione visualizzazione grafo...\n"
     ]
    }
   ],
   "source": [
    "### üìù Esempio 1: Documento Semplice\n",
    "\n",
    "# %%\n",
    "# Inizializza l'anonimizzatore (solo regex per test rapido)\n",
    "print(\"üöÄ Inizializzazione sistema di anonimizzazione...\")\n",
    "anonimizer = NERAnonimizer(use_ner=False, verbose=True)\n",
    "\n",
    "# Testo di esempio\n",
    "testo_esempio_1 = \"\"\"\n",
    "Mario Rossi, nato il 15/03/1985, risiede in Via Roma 123, Milano.\n",
    "Il suo numero di telefono √® 02-1234567 e la sua email √® mario.rossi@gmail.com.\n",
    "Ha un codice fiscale RSSMRA85C15F205X e partita IVA 12345678901.\n",
    "Il suo IBAN √® IT60X0542811101000000123456 e paga sempre con la carta 4532-1234-5678-9012.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\nüìÑ TESTO ORIGINALE:\")\n",
    "print(\"-\" * 50)\n",
    "print(testo_esempio_1)\n",
    "\n",
    "# Anonimizza il documento\n",
    "print(\"\\nüîÑ Processamento in corso...\")\n",
    "testo_anonimizzato, entit√†_trovate = anonimizer.anonymize(testo_esempio_1, doc_id=\"documento_esempio_1\")\n",
    "\n",
    "print(\"\\nüîí TESTO ANONIMIZZATO:\")\n",
    "print(\"-\" * 50)\n",
    "print(testo_anonimizzato)\n",
    "\n",
    "print(f\"\\nüéØ ENTIT√Ä IDENTIFICATE ({len(entit√†_trovate)}):\")\n",
    "print(\"-\" * 50)\n",
    "for placeholder, valore_originale in entit√†_trovate.items():\n",
    "    tipo_entit√† = placeholder.split('[')[1].split('_')[0]\n",
    "    print(f\"üî∏ {tipo_entit√†}: {valore_originale} ‚Üí {placeholder}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### üìä Visualizzazione Risultati Esempio 1\n",
    "\n",
    "# %%\n",
    "# Mostra riassunto dettagliato\n",
    "anonimizer.print_detailed_summary()\n",
    "\n",
    "# Visualizza il grafo\n",
    "print(\"\\nüé® Generazione visualizzazione grafo...\")\n",
    "anonimizer.visualize_graph(\n",
    "    layout_type='spring',\n",
    "    figsize=(16, 10),\n",
    "    title=\"üîí Grafo Anonimizzazione - Documento Esempio 1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8dbf3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Processamento documenti multipli...\n",
      "============================================================\n",
      "\n",
      "üìÑ Processando: fattura_001\n",
      "----------------------------------------\n",
      "‚úÖ Processato documento: 6 entit√† trovate\n",
      "‚úÖ Trovate 6 entit√†\n",
      "   üî∏ DATA: 12/01/2024\n",
      "   üî∏ IMPORTO: 1.250,00‚Ç¨\n",
      "   üî∏ INDIRIZZO: Via Garibaldi 45\n",
      "   ... e altre 3 entit√†\n",
      "\n",
      "üìÑ Processando: contratto_002\n",
      "----------------------------------------\n",
      "‚úÖ Processato documento: 5 entit√† trovate\n",
      "‚úÖ Trovate 5 entit√†\n",
      "   üî∏ DATA: 22/08/1990\n",
      "   üî∏ IMPORTO: 2.500,00‚Ç¨\n",
      "   üî∏ INDIRIZZO: Corso Italia 88\n",
      "   ... e altre 2 entit√†\n",
      "\n",
      "üìÑ Processando:     preventivo_003\n",
      "----------------------------------------\n",
      "‚úÖ Processato documento: 6 entit√† trovate\n",
      "‚úÖ Trovate 6 entit√†\n",
      "   üî∏ IMPORTO: 15.750,00‚Ç¨\n",
      "   üî∏ INDIRIZZO: Via Montenapoleone 12\n",
      "   üî∏ EMAIL: info@techsolutions.it\n",
      "   ... e altre 3 entit√†\n",
      "\n",
      "üéØ RISULTATI COMPLESSIVI:\n",
      "----------------------------------------\n",
      "üìÑ Documenti processati: 3\n",
      "üéØ Entit√† totali trovate: 17\n"
     ]
    }
   ],
   "source": [
    "### üìù Esempio 2: Documenti Multipli\n",
    "\n",
    "# %%\n",
    "# Aggiungi pi√π documenti per testare le relazioni\n",
    "documenti_esempio = {\n",
    "    \"fattura_001\": \"\"\"\n",
    "    Fattura n. 2024/001 del 12/01/2024\n",
    "    Cliente: Giulia Verdi - Via Garibaldi 45, Roma\n",
    "    Email: giulia.verdi@email.it - Tel: 06-9876543\n",
    "    Codice Fiscale: VRDGLI90A52H501Z\n",
    "    Importo: 1.250,00‚Ç¨\n",
    "    \"\"\",\n",
    "    \n",
    "    \"contratto_002\": \"\"\"\n",
    "    Contratto di lavoro - Marco Bianchi\n",
    "    Nato il 22/08/1990, residente in Corso Italia 88, Torino\n",
    "    Telefono: 011-555-1234, Email: m.bianchi@company.com\n",
    "    Codice Fiscale: BNCMRC90M22L219K\n",
    "    Stipendio: 2.500,00‚Ç¨ mensili\n",
    "    \"\"\",\n",
    "    \n",
    "    \"    preventivo_003\": \"\"\"\n",
    "    Preventivo n. 2024-PRV-003\n",
    "    Azienda: Tech Solutions SRL - P.IVA 98765432101\n",
    "    Via Montenapoleone 12, Milano - Tel: 02-1111222\n",
    "    Email: info@techsolutions.it\n",
    "    Importo totale: 15.750,00‚Ç¨\n",
    "    IBAN: IT75B0300203280123456789012\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "print(\"üìö Processamento documenti multipli...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Processa tutti i documenti\n",
    "risultati_multipli = {}\n",
    "for doc_id, contenuto in documenti_esempio.items():\n",
    "    print(f\"\\nüìÑ Processando: {doc_id}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    testo_anonimizzato, entit√† = anonimizer.anonymize(contenuto, doc_id=doc_id)\n",
    "    risultati_multipli[doc_id] = {\n",
    "        'testo_originale': contenuto,\n",
    "        'testo_anonimizzato': testo_anonimizzato,\n",
    "        'entit√†': entit√†\n",
    "    }\n",
    "    \n",
    "    print(f\"‚úÖ Trovate {len(entit√†)} entit√†\")\n",
    "    \n",
    "    # Mostra le prime 3 entit√† trovate\n",
    "    for i, (placeholder, valore) in enumerate(list(entit√†.items())[:3]):\n",
    "        tipo = placeholder.split('[')[1].split('_')[0]\n",
    "        print(f\"   üî∏ {tipo}: {valore}\")\n",
    "    \n",
    "    if len(entit√†) > 3:\n",
    "        print(f\"   ... e altre {len(entit√†) - 3} entit√†\")\n",
    "\n",
    "print(f\"\\nüéØ RISULTATI COMPLESSIVI:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"üìÑ Documenti processati: {len(risultati_multipli)}\")\n",
    "print(f\"üéØ Entit√† totali trovate: {sum(len(r['entit√†']) for r in risultati_multipli.values())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4708d4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üîí SISTEMA DI ANONIMIZZAZIONE - REPORT DETTAGLIATO\n",
      "======================================================================\n",
      "\n",
      "üìä STATISTICHE GENERALI\n",
      "------------------------------\n",
      "üîó Nodi nel grafo: 27\n",
      "üîó Collegamenti: 39\n",
      "üìÑ Documenti processati: 4\n",
      "üéØ Entit√† totali trovate: 25\n",
      "‚è±Ô∏è Tempo elaborazione: 0.00 secondi\n",
      "\n",
      "üìã DISTRIBUZIONE PER TIPO\n",
      "------------------------------\n",
      "üìÇ Categoria: 9\n",
      "üìÑ Documento: 4\n",
      "üéØ INDIRIZZO: 2\n",
      "üéØ EMAIL: 2\n",
      "üéØ IMPORTO: 2\n",
      "üéØ PARTITA_IVA: 2\n",
      "üéØ CODICE_FISCALE: 2\n",
      "üéØ TELEFONO: 1\n",
      "üéØ DATA: 1\n",
      "üéØ IBAN: 1\n",
      "üéØ CARTA_CREDITO: 1\n",
      "\n",
      "üìÑ DETTAGLI ENTIT√Ä\n",
      "------------------------------\n",
      "   üî∏ [DATA_0] (DATA)\n",
      "      üìù Testo: 22/08/1990\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134573\n",
      "   üî∏ DATA (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [INDIRIZZO_1] (INDIRIZZO)\n",
      "      üìù Testo: Via Montenapoleone 12\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134761\n",
      "   üî∏ INDIRIZZO (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [EMAIL_2] (EMAIL)\n",
      "      üìù Testo: info@techsolutions.it\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134775\n",
      "   üî∏ EMAIL (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [IBAN_3] (IBAN)\n",
      "      üìù Testo: IT75B0300203280123456789012\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134785\n",
      "   üî∏ IBAN (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [TELEFONO_4] (TELEFONO)\n",
      "      üìù Testo: 02-1111222\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134797\n",
      "   üî∏ TELEFONO (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [CODICE_FISCALE_5] (CODICE_FISCALE)\n",
      "      üìù Testo: VRDGLI90A52H501Z\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134447\n",
      "   üî∏ CODICE_FISCALE (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [CARTA_CREDITO_6] (CARTA_CREDITO)\n",
      "      üìù Testo: 4532-1234-5678-9012\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864407\n",
      "   üî∏ CARTA_CREDITO (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [PARTITA_IVA_7] (PARTITA_IVA)\n",
      "      üìù Testo: 12345678901\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864423\n",
      "   üî∏ PARTITA_IVA (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ documento_esempio_1 (Documento)\n",
      "      üìù Testo: N/A\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:26.864440\n",
      "   üî∏ [IMPORTO_1] (IMPORTO)\n",
      "      üìù Testo: 2.500,00‚Ç¨\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134587\n",
      "   üî∏ IMPORTO (Categoria)\n",
      "      üìù Testo: N/A\n",
      "   üî∏ [INDIRIZZO_2] (INDIRIZZO)\n",
      "      üìù Testo: Corso Italia 88\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134600\n",
      "   üî∏ [EMAIL_3] (EMAIL)\n",
      "      üìù Testo: m.bianchi@company.com\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134613\n",
      "   üî∏ fattura_001 (Documento)\n",
      "      üìù Testo: N/A\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134474\n",
      "   üî∏ [CODICE_FISCALE_4] (CODICE_FISCALE)\n",
      "      üìù Testo: BNCMRC90M22L219K\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134638\n",
      "   üî∏ contratto_002 (Documento)\n",
      "      üìù Testo: N/A\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134660\n",
      "   üî∏ [IMPORTO_0] (IMPORTO)\n",
      "      üìù Testo: 15.750,00‚Ç¨\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134747\n",
      "   üî∏ [PARTITA_IVA_5] (PARTITA_IVA)\n",
      "      üìù Testo: 98765432101\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134819\n",
      "   üî∏     preventivo_003 (Documento)\n",
      "      üìù Testo: N/A\n",
      "      ‚è∞ Creato: 2025-07-03T15:49:43.134829\n",
      "\n",
      "üé® Generazione visualizzazione grafo completo...\n",
      "üìä ANALISI DETTAGLIATA DEI RISULTATI\n",
      "============================================================\n",
      "\n",
      "üìã Top 5 tipi di entit√† pi√π comuni:\n",
      "ü•á INDIRIZZO: 2 occorrenze\n",
      "ü•à IMPORTO: 2 occorrenze\n",
      "ü•â EMAIL: 2 occorrenze\n",
      "üèÖ PARTITA_IVA: 2 occorrenze\n",
      "üèÖ CODICE_FISCALE: 2 occorrenze\n",
      "\n",
      "üìè Lunghezza media del testo per tipo:\n",
      "   üìê IBAN: 27.0 caratteri\n",
      "   üìê EMAIL: 21.0 caratteri\n",
      "   üìê CARTA_CREDITO: 19.0 caratteri\n",
      "   üìê INDIRIZZO: 18.0 caratteri\n",
      "   üìê CODICE_FISCALE: 16.0 caratteri\n"
     ]
    }
   ],
   "source": [
    "### üé® Visualizzazione Grafo Completo\n",
    "\n",
    "# %%\n",
    "# Mostra il riassunto completo del sistema\n",
    "anonimizer.print_detailed_summary()\n",
    "\n",
    "# Visualizza il grafo completo con tutti i documenti\n",
    "print(\"\\nüé® Generazione visualizzazione grafo completo...\")\n",
    "anonimizer.visualize_graph(\n",
    "    layout_type='spring',\n",
    "    figsize=(18, 12),\n",
    "    title=\"üï∏Ô∏è Grafo Completo - Relazioni tra Documenti ed Entit√†\"\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ### üìä Analisi Avanzata dei Risultati\n",
    "\n",
    "# %%\n",
    "# Crea un'analisi dettagliata dei tipi di entit√† pi√π comuni\n",
    "print(\"üìä ANALISI DETTAGLIATA DEI RISULTATI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stats = anonimizer.get_graph_stats()\n",
    "\n",
    "# Crea un DataFrame per l'analisi\n",
    "entit√†_data = []\n",
    "for node, data in anonimizer.G.nodes(data=True):\n",
    "    if data.get('tipo') not in ['Documento', 'Categoria']:\n",
    "        entit√†_data.append({\n",
    "            'ID': node,\n",
    "            'Tipo': data.get('tipo', 'Unknown'),\n",
    "            'Testo_Originale': data.get('testo_originale', 'N/A'),\n",
    "            'Lunghezza': len(data.get('testo_originale', '')),\n",
    "            'Timestamp': data.get('timestamp', 'N/A')\n",
    "        })\n",
    "\n",
    "df_entit√† = pd.DataFrame(entit√†_data)\n",
    "\n",
    "if len(df_entit√†) > 0:\n",
    "    print(\"\\nüìã Top 5 tipi di entit√† pi√π comuni:\")\n",
    "    tipo_counts = df_entit√†['Tipo'].value_counts()\n",
    "    for i, (tipo, count) in enumerate(tipo_counts.head().items(), 1):\n",
    "        emoji = \"ü•á\" if i == 1 else \"ü•à\" if i == 2 else \"ü•â\" if i == 3 else \"üèÖ\"\n",
    "        print(f\"{emoji} {tipo}: {count} occorrenze\")\n",
    "    \n",
    "    print(f\"\\nüìè Lunghezza media del testo per tipo:\")\n",
    "    lunghezza_media = df_entit√†.groupby('Tipo')['Lunghezza'].mean().sort_values(ascending=False)\n",
    "    for tipo, media in lunghezza_media.head().items():\n",
    "        print(f\"   üìê {tipo}: {media:.1f} caratteri\")\n",
    "    \n",
    "    # Visualizza distribuzione con un grafico a torta\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Subplot 1: Grafico a torta\n",
    "    plt.subplot(2, 2, 1)\n",
    "    colors = [ENTITY_COLORS.get(tipo, ENTITY_COLORS['default']) for tipo in tipo_counts.index]\n",
    "    plt.pie(tipo_counts.values, labels=tipo_counts.index, colors=colors, autopct='%1.1f%%')\n",
    "    plt.title('üìä Distribuzione Tipi di Entit√†')\n",
    "    \n",
    "    # Subplot 2: Grafico a barre\n",
    "    plt.subplot(2, 2, 2)\n",
    "    bars = plt.bar(tipo_counts.index, tipo_counts.values, color=colors)\n",
    "    plt.title('üìà Frequenza Tipi di Entit√†')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Numero di Occorrenze')\n",
    "    \n",
    "    # Aggiungi valori sulle barre\n",
    "    for bar, value in zip(bars, tipo_counts.values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                str(value), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Subplot 3: Lunghezza media\n",
    "    plt.subplot(2, 2, 3)\n",
    "    colors_len = [ENTITY_COLORS.get(tipo, ENTITY_COLORS['default']) for tipo in lunghezza_media.index]\n",
    "    plt.barh(lunghezza_media.index, lunghezza_media.values, color=colors_len)\n",
    "    plt.title('üìè Lunghezza Media Testo')\n",
    "    plt.xlabel('Caratteri')\n",
    "    \n",
    "    # Subplot 4: Timeline (se disponibile)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    if 'Timestamp' in df_entit√†.columns and df_entit√†['Timestamp'].notna().any():\n",
    "        # Crea un grafico temporale semplificato\n",
    "        plt.hist(range(len(df_entit√†)), bins=min(10, len(df_entit√†)), alpha=0.7, color='skyblue')\n",
    "        plt.title('‚è∞ Timeline Processamento')\n",
    "        plt.xlabel('Ordine di Processamento')\n",
    "        plt.ylabel('Numero di Entit√†')\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'Timeline non disponibile', ha='center', va='center', transform=plt.gca().transAxes)\n",
    "        plt.title('‚è∞ Timeline Processamento')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Nessuna entit√† trovata per l'analisi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4835b365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç QUERY AVANZATE SUL GRAFO\n",
      "==================================================\n",
      "\n",
      "üìÑ Documenti con il maggior numero di entit√†:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NERAnonimizer' object has no attribute 'get_document_entities'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m node, data \u001b[38;5;129;01min\u001b[39;00m anonimizer.G.nodes(data=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data.get(\u001b[33m'\u001b[39m\u001b[33mtipo\u001b[39m\u001b[33m'\u001b[39m) == \u001b[33m'\u001b[39m\u001b[33mDocumento\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m         num_entit√† = \u001b[38;5;28mlen\u001b[39m(\u001b[43manonimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_document_entities\u001b[49m(node))\n\u001b[32m     13\u001b[39m         documenti_con_entit√†.append((node, num_entit√†))\n\u001b[32m     15\u001b[39m documenti_con_entit√†.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m1\u001b[39m], reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NERAnonimizer' object has no attribute 'get_document_entities'"
     ]
    }
   ],
   "source": [
    "### üîç Query Avanzate sul Grafo\n",
    "\n",
    "# %%\n",
    "print(\"üîç QUERY AVANZATE SUL GRAFO\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Query 1: Trova documenti con pi√π entit√†\n",
    "print(\"\\nüìÑ Documenti con il maggior numero di entit√†:\")\n",
    "documenti_con_entit√† = []\n",
    "for node, data in anonimizer.G.nodes(data=True):\n",
    "    if data.get('tipo') == 'Documento':\n",
    "        num_entit√† = len(anonimizer.get_document_entities(node))\n",
    "        documenti_con_entit√†.append((node, num_entit√†))\n",
    "\n",
    "documenti_con_entit√†.sort(key=lambda x: x[1], reverse=True)\n",
    "for doc, num in documenti_con_entit√†:\n",
    "    print(f\"   üìã {doc}: {num} entit√†\")\n",
    "\n",
    "# Query 2: Trova entit√† condivise tra documenti\n",
    "print(f\"\\nüîó Tipi di entit√† presenti in pi√π documenti:\")\n",
    "tipi_per_documento = {}\n",
    "for doc, num in documenti_con_entit√†:\n",
    "    entit√†_doc = anonimizer.get_document_entities(doc)\n",
    "    tipi_doc = set()\n",
    "    for entit√† in entit√†_doc:\n",
    "        if anonimizer.G.has_node(entit√†):\n",
    "            tipo = anonimizer.G.nodes[entit√†].get('tipo', 'Unknown')\n",
    "            tipi_doc.add(tipo)\n",
    "    tipi_per_documento[doc] = tipi_doc\n",
    "\n",
    "# Trova tipi comuni\n",
    "tutti_i_tipi = set()\n",
    "for tipi in tipi_per_documento.values():\n",
    "    tutti_i_tipi.update(tipi)\n",
    "\n",
    "for tipo in tutti_i_tipi:\n",
    "    documenti_con_tipo = [doc for doc, tipi in tipi_per_documento.items() if tipo in tipi]\n",
    "    if len(documenti_con_tipo) > 1:\n",
    "        print(f\"   üî∏ {tipo}: presente in {len(documenti_con_tipo)} documenti\")\n",
    "\n",
    "# Query 3: Statistiche di centralit√†\n",
    "print(f\"\\nüéØ Nodi pi√π centrali (degree centrality):\")\n",
    "centrality = nx.degree_centrality(anonimizer.G)\n",
    "sorted_centrality = sorted(centrality.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "for node, score in sorted_centrality[:5]:\n",
    "    node_type = anonimizer.G.nodes[node].get('tipo', 'Unknown')\n",
    "    print(f\"   üî∏ {node} ({node_type}): {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "### üíæ Esportazione Risultati\n",
    "\n",
    "# %%\n",
    "print(\"üíæ ESPORTAZIONE RISULTATI\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Esporta in diversi formati\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# 1. Esporta in JSON\n",
    "json_file = f\"anonimizzazione_risultati_{timestamp}.json\"\n",
    "anonimizer.export_results(json_file, format='json')\n",
    "\n",
    "# 2. Esporta in CSV\n",
    "csv_file = f\"entit√†_estratte_{timestamp}.csv\"\n",
    "anonimizer.export_results(csv_file, format='csv')\n",
    "\n",
    "# 3. Esporta grafo per Gephi\n",
    "gexf_file = f\"grafo_entit√†_{timestamp}.gexf\"\n",
    "anonimizer.export_results(gexf_file, format='gexf')\n",
    "\n",
    "# 4. Salva visualizzazione\n",
    "img_file = f\"grafo_visualizzazione_{timestamp}.png\"\n",
    "anonimizer.visualize_graph(\n",
    "    layout_type='spring',\n",
    "    figsize=(16, 12),\n",
    "    save_path=img_file,\n",
    "    title=\"üîí Sistema di Anonimizzazione - Report Finale\"\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Tutti i file sono stati esportati con timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26527d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### üõ†Ô∏è Funzioni di Utilit√†\n",
    "\n",
    "# %%\n",
    "def crea_report_markdown(anonimizer, filename=None):\n",
    "    \"\"\"\n",
    "    üìù Crea un report markdown completo\n",
    "    \"\"\"\n",
    "    if filename is None:\n",
    "        filename = f\"report_anonimizzazione_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n",
    "    \n",
    "    stats = anonimizer.get_graph_stats()\n",
    "    \n",
    "    report = f\"\"\"# üîí Report Sistema di Anonimizzazione\n",
    "\n",
    "## üìä Statistiche Generali\n",
    "- **Nodi nel grafo**: {stats['numero_nodi']}\n",
    "- **Collegamenti**: {stats['numero_collegamenti']}\n",
    "- **Documenti processati**: {anonimizer.stats['documenti_processati']}\n",
    "- **Entit√† totali**: {anonimizer.stats['entit√†_trovate']}\n",
    "- **Tempo elaborazione**: {anonimizer.stats['tempo_elaborazione']:.2f} secondi\n",
    "\n",
    "## üìã Distribuzione per Tipo\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    for tipo, count in sorted(stats['entit√†_per_tipo'].items(), key=lambda x: x[1], reverse=True):\n",
    "        report += f\"- **{tipo}**: {count}\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "## üéØ Entit√† Identificate\n",
    "\n",
    "| ID | Tipo | Testo Originale | Timestamp |\n",
    "|----|----|--------|-----------|\n",
    "\"\"\"\n",
    "    \n",
    "    for node, data in anonimizer.G.nodes(data=True):\n",
    "        if data.get('tipo') not in ['Documento', 'Categoria']:\n",
    "            tipo = data.get('tipo', 'Unknown')\n",
    "            testo = data.get('testo_originale', 'N/A')[:30] + \"...\" if len(data.get('testo_originale', '')) > 30 else data.get('testo_originale', 'N/A')\n",
    "            timestamp = data.get('timestamp', 'N/A')\n",
    "            report += f\"| {node} | {tipo} | {testo} | {timestamp} |\\n\"\n",
    "    \n",
    "    report += f\"\"\"\n",
    "## üîó Relazioni nel Grafo\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    for edge in anonimizer.G.edges(data=True):\n",
    "        source, target, data = edge\n",
    "        relation = data.get('relazione', 'unknown')\n",
    "        report += f\"- {source} **{relation}** {target}\\n\"\n",
    "    \n",
    "    # Salva il report\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(f\"üìù Report markdown salvato: {filename}\")\n",
    "    return filename\n",
    "\n",
    "def test_performance(anonimizer, num_tests=100):\n",
    "    \"\"\"\n",
    "    ‚ö° Test di performance\n",
    "    \"\"\"\n",
    "    print(\"‚ö° TEST DI PERFORMANCE\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    testi_test = [\n",
    "        \"Mario Rossi, email: mario@email.com, tel: 123456789\",\n",
    "        \"Giulia Verdi, nata il 15/03/1990, CF: VRDGLI90C55H501Z\",\n",
    "        \"Azienda XYZ, P.IVA: 12345678901, Via Roma 123\",\n",
    "        \"Fattura 2024/001, importo: 1.500,00‚Ç¨, IBAN: IT60X0542811101000000123456\"\n",
    "    ]\n",
    "    \n",
    "    import time\n",
    "    \n",
    "    tempi = []\n",
    "    for i in range(num_tests):\n",
    "        testo = testi_test[i % len(testi_test)]\n",
    "        \n",
    "        start = time.time()\n",
    "        anonimizer.anonymize(testo, doc_id=f\"test_{i}\")\n",
    "        end = time.time()\n",
    "        \n",
    "        tempi.append(end - start)\n",
    "    \n",
    "    print(f\"üìä Risultati test su {num_tests} documenti:\")\n",
    "    print(f\"   ‚è±Ô∏è Tempo medio: {np.mean(tempi):.4f} secondi\")\n",
    "    print(f\"   ‚ö° Tempo minimo: {np.min(tempi):.4f} secondi\")\n",
    "    print(f\"   üêå Tempo massimo: {np.max(tempi):.4f} secondi\")\n",
    "    print(f\"   üìè Deviazione standard: {np.std(tempi):.4f} secondi\")\n",
    "    \n",
    "    # Visualizza distribuzione tempi\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(tempi, bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    plt.title('üìä Distribuzione Tempi di Elaborazione')\n",
    "    plt.xlabel('Tempo (secondi)')\n",
    "    plt.ylabel('Frequenza')\n",
    "    plt.axvline(np.mean(tempi), color='red', linestyle='--', label=f'Media: {np.mean(tempi):.4f}s')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18a579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### üß™ Test Finali e Performance\n",
    "\n",
    "# Genera report markdown\n",
    "print(\"üìù Generazione report markdown...\")\n",
    "report_file = crea_report_markdown(anonimizer)\n",
    "\n",
    "# Test di performance (versione ridotta per il notebook)\n",
    "print(\"\\n‚ö° Avvio test di performance...\")\n",
    "test_performance(anonimizer, num_tests=50)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### üéâ Conclusioni e Prossimi Passi\n",
    "\n",
    "# %%\n",
    "print(\"üéâ CONCLUSIONI DEL SISTEMA DI ANONIMIZZAZIONE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "stats_finali = anonimizer.get_graph_stats()\n",
    "\n",
    "print(f\"\"\"\n",
    "‚úÖ SISTEMA COMPLETAMENTE OPERATIVO!\n",
    "\n",
    "üìä RISULTATI FINALI:\n",
    "   üîó Nodi creati: {stats_finali['numero_nodi']}\n",
    "   üîó Relazioni mappate: {stats_finali['numero_collegamenti']}\n",
    "   üìÑ Documenti processati: {anonimizer.stats['documenti_processati']}\n",
    "   üéØ Entit√† identificate: {anonimizer.stats['entit√†_trovate']}\n",
    "   ‚è±Ô∏è Tempo totale: {anonimizer.stats['tempo_elaborazione']:.2f} secondi\n",
    "\n",
    "üöÄ FUNZIONALIT√Ä IMPLEMENTATE:\n",
    "   ‚úÖ Riconoscimento entit√† con regex personalizzate\n",
    "   ‚úÖ Supporto per modelli NER (opzionale)\n",
    "   ‚úÖ Creazione automatica di grafi delle relazioni\n",
    "   ‚úÖ Visualizzazioni avanzate con matplotlib\n",
    "   ‚úÖ Analisi statistiche dettagliate\n",
    "   ‚úÖ Esportazione in multipli formati (JSON, CSV, GEXF)\n",
    "   ‚úÖ Report automatici in Markdown\n",
    "   ‚úÖ Test di performance integrati\n",
    "\n",
    "üîÆ PROSSIMI PASSI SUGGERITI:\n",
    "   üî∏ Integrazione con interfaccia Streamlit\n",
    "   üî∏ Supporto per file PDF e DOCX\n",
    "   üî∏ Modelli NER personalizzati per domini specifici\n",
    "   üî∏ API REST per integrazione in sistemi esterni\n",
    "   üî∏ Dashboard interattiva con Plotly/Dash\n",
    "   üî∏ Backup automatico dei risultati\n",
    "   üî∏ Configurazione pattern regex via file YAML\n",
    "\n",
    "üí° SUGGERIMENTI PER L'USO:\n",
    "   - Usa use_ner=True per documenti con entit√† complesse\n",
    "   - Personalizza i pattern regex in base al dominio\n",
    "   - Esporta in GEXF per analisi avanzate con Gephi\n",
    "   - Salva le visualizzazioni per presentazioni\n",
    "   - Monitora le performance con test regolari\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüéØ Il sistema √® pronto per l'uso in produzione!\")\n",
    "print(\"üìö Consulta la documentazione nelle celle markdown per dettagli aggiuntivi.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
